{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Animal Dataset - v1\n",
    "We will evaluate some **multiclass classification** CNNs to predict the classes of the **Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
    "\n",
    "\n",
    "Target goals:\n",
    "- Proposed CNN's Architecture\n",
    "- Dataset Preprocessing\n",
    "    + Import the image data\n",
    "    + Preprocessing the data\n",
    "        - Image rescaling\n",
    "        - Normalization\n",
    "    + Save the preprocessed data\n",
    "    + Convert the images into a _feature matrix (X)_ and a list of _target labels (y)_\n",
    "- Train CNN\n",
    "    - Use early stopping regularization\n",
    "- Evaluate a simple CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on:\n",
    "- https://stackoverflow.com/a/59076062\n",
    "- https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41809176-c43b-4143-940e-e63e26394fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    \n",
    "# make some random data\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25efbd0-4d14-4f97-84f7-18e6e103a6b9",
   "metadata": {},
   "source": [
    "### 1.3. Dataset\n",
    "**Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61214708-7ce5-4b91-9a2d-86acbd3eef02",
   "metadata": {},
   "source": [
    "#### 1.3.1 Load the dataset\n",
    "**Balanced dataset**: _'../datasets/animal-dataset/animals_dataset_balanced.csv'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf64ef0-0c66-47c6-9233-0e8f61fd0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba804a2-aa9f-46a2-83bb-39c82ed01fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('../datasets/animals-dataset/animals_dataset_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf34e3e7-6599-4df5-a4f2-253a61579794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_pathname</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/cane/OIP-u...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/cane/OIP-V...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/cane/OIP-0...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/cane/OIP-b...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/cane/OIP-8...</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/scoiattolo...</td>\n",
       "      <td>squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/scoiattolo...</td>\n",
       "      <td>squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/scoiattolo...</td>\n",
       "      <td>squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/scoiattolo...</td>\n",
       "      <td>squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>../datasets/animals-dataset/raw-img/scoiattolo...</td>\n",
       "      <td>squirrel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_pathname     class\n",
       "0      ../datasets/animals-dataset/raw-img/cane/OIP-u...       dog\n",
       "1      ../datasets/animals-dataset/raw-img/cane/OIP-V...       dog\n",
       "2      ../datasets/animals-dataset/raw-img/cane/OIP-0...       dog\n",
       "3      ../datasets/animals-dataset/raw-img/cane/OIP-b...       dog\n",
       "4      ../datasets/animals-dataset/raw-img/cane/OIP-8...       dog\n",
       "...                                                  ...       ...\n",
       "13995  ../datasets/animals-dataset/raw-img/scoiattolo...  squirrel\n",
       "13996  ../datasets/animals-dataset/raw-img/scoiattolo...  squirrel\n",
       "13997  ../datasets/animals-dataset/raw-img/scoiattolo...  squirrel\n",
       "13998  ../datasets/animals-dataset/raw-img/scoiattolo...  squirrel\n",
       "13999  ../datasets/animals-dataset/raw-img/scoiattolo...  squirrel\n",
       "\n",
       "[14000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e324b-4a1d-48ae-9458-96ea4a7290ff",
   "metadata": {},
   "source": [
    "#### 1.3.2 Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fdfb469-da26-4165-99d5-c0267d9f3c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n",
      "Classes: ['butterfly', 'cat', 'chicken', 'cow', 'dog', 'elephant', 'horse', 'sheep', 'spider', 'squirrel']\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted(dataset_df[\"class\"].unique())\n",
    "n_classes = len(class_names)\n",
    "\n",
    "print(f'Number of classes: {n_classes}')\n",
    "print(f'Classes: {class_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b17035-7d19-4456-b16f-2ea07c87b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples per class\n",
    "dataset_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cac26-25c1-467a-a446-4910a9512320",
   "metadata": {},
   "source": [
    "## 2. Building and Training a CNN via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b87c-b0d8-4079-a16d-5dc72ebf5135",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture\n",
    "That's a simple CNN for _Multiclass Classification_:\n",
    "- **INPUT [64x64x3]**\n",
    "- CONV [32, 4x4x3, 'valid']\n",
    "- RELU\n",
    "- MAX_POOL [2x2, stride=(1,1)]\n",
    "- CONV [32, 4x4x3, 'valid']\n",
    "- RELU => MAX_POOL [2x2, stride=(1,1)]\n",
    "- FLATTEN\n",
    "- FC [256]\n",
    "- RELU => FC [10, 'softmax']  # number of classes\n",
    "\n",
    "- optimizer: SGD with `learning_rate=0.01`\n",
    "- kernel_initializer: \"glorot_uniform\"\n",
    "- bias_initializer: \"zeros\"\n",
    "- **Early stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31de318-1b03-4bf1-81e4-addb3b059e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "def build_cnn(input_shape, n_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(4,4), input_shape=input_shape, activation='relu'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Conv2D(filters=32, kernel_size=(4,4), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d877603-c3b1-4053-854a-7def148cf2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017e44a-1cac-4000-b651-4e137f4d87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a83e6-1a7a-4d73-9c47-149f6e18ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "# vertical\n",
    "plot_model(model, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bc705-b54e-438d-b246-f8fe52501c8a",
   "metadata": {},
   "source": [
    "### 2.2 Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1e3dd-5b2b-4d8f-92aa-fcfabadbf216",
   "metadata": {},
   "source": [
    "- **Image Resizing**\n",
    "    + Since the **input layer's shape** and the **images' shape** ***are different***, we need to **resize** the images to the **input layer's shape**.\n",
    "    + Let's use the function `c2.resize()` for that: https://learnopencv.com/image-resizing-with-opencv/#resize-by-wdith-height\n",
    "- **Intensity (feature) Scaling**\n",
    "    + Animals dataset contain 24-bit color images, i.e., it is a color image where each channel is a 8-bit grayscale image (values from 0 to 255)\n",
    "    + We will simply rescale the values to [0, 1] by dividing them by 255.\n",
    "- **Label Encoder**\n",
    "    + Encode the string classes into class integers from 0 to n_classes-1\n",
    "    + https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "    \n",
    "Create a function that performs all these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8d6c2-a7de-4205-933c-053731e5156a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86694d34-dd62-47ee-8d44-09e7f23b5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, label_encoder = preprocess_animals_dataset(dataset_df, new_dims=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da977ea-5942-4bed-918d-4b591113c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature matrix X: {X.shape}')\n",
    "print(f'Target labels (classes) y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413ad72-5c72-4bb7-8178-8cb990435041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X: {X.min()}')\n",
    "print(f'Max. value of X: {X.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab766d4-d3ca-4ea9-8ba1-c6d5d2610a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd4516-74b5-4e64-8606-b63e91a7ec56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2e582c-bed7-4dcb-ba89-1fee1c85ae91",
   "metadata": {},
   "source": [
    "Since this function may be useful in other notebooks, let's create a **python file/module** to make it available:\n",
    "\n",
    "**File:** `animals_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf259c-d4a5-4892-acde-722f5bcf147f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1882-495b-47f9-bc89-cd2553fcfc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7488d0-7337-4f30-94cd-c139faa90e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature matrix X: {X.shape}')\n",
    "print(f'Target labels (classes) y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd75d04-deb8-49e1-9a69-cd24b40a1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X: {X.min()}')\n",
    "print(f'Max. value of X: {X.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32379f-a626-4605-bc77-c574bece6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522eac0-8884-4713-a5c0-7d06631efcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea86c72-0206-4f5c-9e99-3564d91230d6",
   "metadata": {},
   "source": [
    "#### **Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cd408-9b70-4464-92b9-28dcd33797ef",
   "metadata": {},
   "source": [
    "While _image resizing_ and _feature scaling_ **don't learn** any parameter, our _label encoding_ learns the convertion between _class names_ to _sequential integers_ considering the **entire data**. <br/>\n",
    "To consider a _real scenario_, we shouldn't do that. We should _split the data_ into _training and testing sets_ ***before* applying any preprocessing** to avoid _snooping bias_. <br/>\n",
    "\n",
    "Also, the most indicated way is to create a **Scikit-learn `Pipeline`** to _preprocess our data_. For that, we would have to create a _custom sklearn transformer_ to resize the images as well as for the simple feature normalization, and label encoding. Then, we could use this **preprocessing step** in production to preprocess any data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5497fd-f2a7-4d5c-bb0a-557e2e2aa9b5",
   "metadata": {},
   "source": [
    "### 2.3 Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb21adf-5567-4343-94ce-cd06472171c2",
   "metadata": {},
   "source": [
    "Our dataframe `dataset_df` corresponds to the full formated as a \"table\" with _image pathnames_ and _image classes_ <br/>\n",
    "`X` is our _feature matrix_ which corresponds to the resized normalized images. <br/>\n",
    "`y` is the vector with the true labels (classes) of `X`.\n",
    "\n",
    "Note that each sample `[i]` from `dataset_df` has its corresponding features in `X[i]` and class in `y[i]`. <br/>\n",
    "To save the pathanme from the original image after spliting the dataset, we will split `dataset_df`. <br/>\n",
    "Then, we can recovery the indices from the splitted sets to get our _training_ and _testing numpy arrays_.\n",
    "\n",
    "If the original image pathanmes are not important for you, simply apply `train_test_split` directly over `X` and `y` and be happy =D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7ec09-dff0-4ea6-9db7-f3f2cd66cbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89663438-040e-4508-a31e-33f1e3ad47c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14812b55-0edd-4255-a4a5-ebcd72903ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7fc62-be8a-4bc3-a4bf-b8e825ae9b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235508b8-faeb-4e7b-8c79-87b71bec1131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c0e22e-3431-46da-ac76-0d7f1b88f4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541adc66-0678-46bc-bdba-c4d4d6bb544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training samples' indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9727e-a143-4dc7-90f3-557ce6a3cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the testing samples' indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304eae1-d345-41ab-9d6f-ffd66a118ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training and test numpy arrays from the dataframes' indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a8cd4-aedc-444c-ba97-d20c6f36c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978509d1-32f1-4531-a4d0-18d08459de9a",
   "metadata": {},
   "source": [
    "### 2.4 Save the Training and Testing Sets (included the preprocessed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fdfc9-23f3-479e-9f3b-d3b69d07872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out_dir = '../datasets/animals-dataset/preprocessed'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "dataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\n",
    "np.save(os.path.join(out_dir, 'train_data_64x64x3.npy'), X_train)\n",
    "np.save(os.path.join(out_dir, 'train_labels.npy'), y_train)\n",
    "\n",
    "dataset_df_test.to_csv(os.path.join(out_dir, 'test.csv'), index=False)\n",
    "np.save(os.path.join(out_dir, 'test_data_64x64x3.npy'), X_test)\n",
    "np.save(os.path.join(out_dir, 'test_labels.npy'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1b6ce-3283-46ee-83d1-cce66271eddb",
   "metadata": {},
   "source": [
    "### 2.5 Training with Early Stopping\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378a5ad-de87-4ecd-b738-19a37dc89ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6649b19-d39a-4ede-af51-911181ad0b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f7dc519-947b-492a-bf99-c6638cf75338",
   "metadata": {},
   "source": [
    "#### **Visualizing the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb091e-a508-4a5b-9efa-6da9d1b47b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69952b3-0c62-48ed-9257-ed851d6b828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xticks(range(30))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "history_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xticks(range(30))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc4b9d-d057-4a3d-9b87-142290632c4a",
   "metadata": {},
   "source": [
    "## 3. Evaluating and Predicting New Samples by using our Overfitted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114493b-379d-4407-8f3f-278806a9c9fb",
   "metadata": {},
   "source": [
    "#### **Evaluation**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75d26-ca65-405e-85bf-377a035a82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c74cf-ba92-40a3-9bba-728e893a58a8",
   "metadata": {},
   "source": [
    "#### **Prediction**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ea39-55a6-47c9-a5ae-e8d3e41e6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model.predict(X_test)\n",
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9d666-911d-41e9-9954-f7b844deb99a",
   "metadata": {},
   "source": [
    "#### **Class Prediction**\n",
    "https://stackoverflow.com/a/69503180/7069696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_proba, axis=1)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafc6b3-a9c5-4d6f-972f-4796208ca8de",
   "metadata": {},
   "source": [
    "We got a **poor accuracy** of XXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86de17-0a7a-4de8-b939-6f427e3e5cc7",
   "metadata": {},
   "source": [
    "#### **Visualizing misclassification proportion - inverse of recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc18cd2-0ae2-405a-a828-ae88bb24a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class_name = label_encoder.inverse_transform(y_test)\n",
    "y_test_pred_class_name = label_encoder.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655f83c-da66-48e6-b132-483808b1ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_mask = y_test_class_name != y_test_pred_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169d890-f0e7-45cd-947e-bf7dbd600c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_error = y_test_class_name[misclassification_mask]\n",
    "y_test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb97ccb-5bf4-44e3-bfc7-e2782ccdb887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=y_test_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6d65c-9f3c-493e-959d-ce59b0750f7b",
   "metadata": {},
   "source": [
    "#### **Visualizing some misclassified image**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00197021-3dab-4282-b5b9-ec466a103268",
   "metadata": {},
   "source": [
    "**Sheep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedb5ef-c811-4524-a76e-671654ae0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep_error_mask = misclassification_mask & (y_test_class_name == \"sheep\")\n",
    "\n",
    "np.argwhere(sheep_error_mask)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74abc7-8c28-4069-833c-94d067248be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 70\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c46cec-21a6-4463-9a8f-431bd382b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251e55f-7309-4e7c-aadb-cb4e15717059",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 94\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b17abe-1eaf-461c-aa4f-e516b8e4fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc08df-eaa6-41fe-8f73-bff73495cc56",
   "metadata": {},
   "source": [
    "**Dog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8239921-7753-41b7-803c-b7d6cd20c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_error_mask = misclassification_mask & (y_test_class_name == \"dog\")\n",
    "\n",
    "np.argwhere(dog_error_mask)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a89b2b-018e-4a67-ac7f-01ee8e4496c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 10\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827baad-da63-49d0-8b5b-5640abfba9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c97d6c-b1a3-42da-ada0-5e02ac683fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 16\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4a0ab-471e-4224-a6b4-c524e95ed788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat the experiments considering different:\n",
    "-  values for _learning_rate_ of SGD\n",
    "- optimizers (e.g., 'nadam')\n",
    "- kernel regularizer (e.g., 'l2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
